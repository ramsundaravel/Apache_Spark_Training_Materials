raw = sqlContext.read.json("/public/retail_db_json/order_items")

root
 |-- order_item_id: long (nullable = true)
 |-- order_item_order_id: long (nullable = true)
 |-- order_item_product_id: long (nullable = true)
 |-- order_item_product_price: double (nullable = true)
 |-- order_item_quantity: long (nullable = true)
 |-- order_item_subtotal: double (nullable = true)


 raw.registerTempTable("order_json")

 sqlContext.setConf("spark.sql.shuffle.partitions","5")

 result = sqlContext.sql("select order_item_order_id, average_subtotal, \
 dense_rank() over (order by average_subtotal desc) as rnk from \
 ( select order_item_order_id, avg(order_item_subtotal) as average_subtotal \
 from order_json group by order_item_order_id)inx order by rnk asc")

 resultwrite = result.rdd.map(lambda x : ",".join([str(i) for i in x]))

 resultwrite.repartition(3).saveAsTextFile("/user/ramkarthik/ram/mock/jsonexample")
